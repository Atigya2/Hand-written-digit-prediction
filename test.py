# -*- coding: utf-8 -*-
"""handwritten_digit_prediction_by_neural_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17JJB2OxKy54e2G59y9DdV3-NHH81A8Wo
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import tensorflow as tf
from tensorflow import keras

(X_train, Y_train) , (X_test, Y_test) = keras.datasets.mnist.load_data()

len(X_train)

len(X_test)

X_train.shape

X_train

plt.matshow(X_train[0])

Y_train[0]

for i in range(5):
  plt.matshow(X_train[i])

#scaling our dataset

X_train = X_train/255
X_test = X_test/255

X_train_flattened = X_train.reshape(len(X_train),28*28)
X_train_flattened.shape

X_test_flattened = X_test.reshape(len(X_test),28*28)
X_test_flattened.shape

X_train[0]

#a simple neural network consisting of
#an input layer and an output layer

model = keras.Sequential([
      keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')  
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.fit(X_train_flattened, Y_train, epochs=5)

y_predicted = model.predict(X_test_flattened)

sc = model.evaluate(X_test_flattened , Y_test)
sc

plt.matshow(X_test[0])

y_predicted[0]

np.argmax(y_predicted[0])

plt.matshow(X_test[3001])

np.argmax(y_predicted[3001])

y_pred_labels = [np.argmax(i) for i in y_predicted]

cm = tf.math.confusion_matrix(labels=Y_test, predictions=y_pred_labels)

import seaborn as sns

plt.figure(figsize=(10,7))
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted Values')
plt.ylabel('Real Values')

#a neural network consisting of
#an input layer, one hidden layer and an output layer

model = keras.Sequential([
      keras.layers.Dense(100, input_shape=(784,), activation='relu'),
      keras.layers.Dense(10, activation='sigmoid')  
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.fit(X_train_flattened, Y_train, epochs=5)

model.evaluate(X_test_flattened, Y_test)

y_pred = model.predict(X_test_flattened)

y_pred_labels = [np.argmax(i) for i in y_pred]
ccm = tf.math.confusion_matrix(labels=Y_test , predictions=y_pred_labels)


plt.figure(figsize=(10,7))
sns.heatmap(cm , annot=True , fmt='d')
plt.xlabel('Predicted Values')
plt.ylabel('Real Values')

#a neural network consisting of
#an input layer, one hidden layer and an output layer

model = keras.Sequential([
      keras.layers.Flatten(input_shape=(28,28)),
      keras.layers.Dense(100, activation='relu'),
      keras.layers.Dense(10, activation='sigmoid')  
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.fit(X_train, Y_train, epochs=10)

model.evaluate(X_test, Y_test)

y_pred = model.predict(X_test)

y_pred_labels = [np.argmax(i) for i in y_pred]
ccm = tf.math.confusion_matrix(labels=Y_test , predictions=y_pred_labels)


plt.figure(figsize=(10,7))
sns.heatmap(cm , annot=True , fmt='d')
plt.xlabel('Predicted Values')
plt.ylabel('Real Values')

model = keras.Sequential([
      keras.layers.Flatten(input_shape=(28,28)),
      keras.layers.Dense(300, activation='relu'),
      keras.layers.Dense(100, activation='relu'),
      keras.layers.Dense(10, activation='sigmoid')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.fit(X_train, Y_train, epochs=5)

model.evaluate(X_test, Y_test)

y_pred = model.predict(X_test)

y_pred_labels = [np.argmax(i) for i in y_pred]
ccm = tf.math.confusion_matrix(labels=Y_test , predictions=y_pred_labels)


plt.figure(figsize=(10,7))
sns.heatmap(cm , annot=True , fmt='d')
plt.xlabel('Predicted Values')
plt.ylabel('Real Values')